{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# Splitting training and test sets\n",
    "# ================================================================================\n",
    "# you will need to do lots of data cleaning and preparation before any analysis. I recommend that you do this first \n",
    "# to the entire dataset, then apply the sampling commands above to the cleaned data set, \n",
    "# to get your test and train samples\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "data=pd.read_excel('caschool.xlsx')\n",
    "\n",
    "\n",
    "data=data.iloc[:, :18]\n",
    "\n",
    "\n",
    "#490155963\n",
    "#490161470\n",
    "#490172878\n",
    "state=490172878+490161470+490155963 # replace this number with the sum of the student IDs for the members of the group\n",
    "print(state)\n",
    "\n",
    "\n",
    "train = data.sample(frac=0.8, random_state=state)\n",
    "test = data[data.index.isin(train.index)==False].copy() # Only for prediction\n",
    "\n",
    "train=train.reset_index(drop=True)\n",
    "test=test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "data.shape\n",
    "data.head\n",
    "data.info()\n",
    "\n",
    "variables=['testscr','read_scr','math_scr','str','enrl_tot','teachers','calw_pct','meal_pct','computer','comp_stu','expn_stu','avginc','el_pct']\n",
    "with sns.axes_style('white'):\n",
    "    g=sns.pairplot(train[variables], kind='reg', \n",
    "                   plot_kws={'scatter_kws' :{'color': sns.color_palette('Blues')[-1], 'alpha': 0.4}})\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data['gr_span'],data['testscr'],palette='Blues')\n",
    "\n",
    "sns.boxplot(data['county'],data['testscr'],palette='Blues')\n",
    "\n",
    "sns.boxplot(data['district'],data['testscr'],palette='Blues')\n",
    "\n",
    "#data transformation\n",
    "#dependent/response variable\n",
    "#box-cox\n",
    "y,lmbda=stats.boxcox(train['testscr'])\n",
    "train['BoxCoxtest']=((train['testscr']**lmbda-1)/lmbda)\n",
    "#log\n",
    "train['log_testscr']=np.log(train['testscr'])\n",
    "train['log_calw_pct']=np.log(train['calw_pct'])\n",
    "train['log_comput_stu']=np.log(train['comput_stu'])\n",
    "train['log_expn_stu']=np.log(train['expn_stu'])\n",
    "train['log_avginc']=np.log(train['avginc'])\n",
    "eliminate nan\n",
    "train=train[train['log_testscr']>=0]\n",
    "train=train[train['BoxCoxtest']>=0]\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# set a grey background (use sns.set_theme() if seaborn version 0.11.0 or above) \n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.histplot(data=train, x=\"testscr\", color=\"skyblue\", label=\"test score\", kde=True)\n",
    "plt.show()\n",
    "#it does not seem to need a transformation for response variable, but we can explore\n",
    "\n",
    "sns.histplot(data=train, x=\"log_testscr\", color=\"skyblue\", label=\"log test score\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=train, x=\"BoxCoxtest\", color=\"skyblue\", label=\"BoxCox test score\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=train, x=\"str\", color=\"skyblue\", label=\"student teacher ratio\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=train, x=\"log_str\", color=\"skyblue\", label=\"log student teacher ratio\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=train, x=\"calw_pct\", color=\"skyblue\", label=\"percent quality for CalWORKS\", kde=True)\n",
    "train[np.isfinite(train['log_cal'])]\n",
    "plt.hist(train[np.isfinite(train['log_cal'])].values)\n",
    "plt.hist(train['log_cal'].dropna().values)\n",
    "sns.histplot(data=train, x=\"log_cal\", color=\"skyblue\", label=\"log percent quality for CalWORKS\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "train['log_cal']=np.log(train['calw_pct'])\n",
    "#train=train[train['log_cal']>=0]\n",
    "\n",
    "sns.histplot(data=train, x=\"meal_pct\", color=\"skyblue\", label=\"percent quality for reduced price lunch\", kde=True)\n",
    "#sns.histplot(data=train, x=\"log_meal\", color=\"skyblue\", label=\"log percent quality for reduced price lunch\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "train['log_meal']=np.log(train['meal_pct'])\n",
    "#train=train[train['log_meal']>=0]\n",
    "sns.histplot(data=train, x=\"computer\", color=\"skyblue\", label=\"number of computers\", kde=True)\n",
    "#sns.histplot(data=train, x=\"log_comp\", color=\"skyblue\", label=\"log of number of computers\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=train, x=\"comp_stu\", color=\"skyblue\", label=\"computer per student\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "train['log_exp']=np.log(train['expn_stu'])\n",
    "sns.histplot(data=train, x=\"log_exp\", color=\"skyblue\", label=\"log expenditure per student\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "train['log_avg']=np.log(train['avginc'])\n",
    "sns.histplot(data=train, x=\"log_avg\", color=\"skyblue\", label=\"log district average income\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=train, x=\"el_pct\", color=\"skyblue\", label=\"percent of English learners\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "#based on above observations, we can see that clwpct, computer, expstud, avginc, and elpct 5 predictors may need log-transformation\n",
    "train.iloc[np.argmax(train.computer),:]\n",
    "#some outliers exist \n",
    "#train = train.drop([227])\n",
    "#list(np.argsort(-train_1.enrl_tot)[0:10])\n",
    "#train_1 = train.drop([list(np.argsort(-train_1.enrl_tot)[0:9])], axis = 0)\n",
    "train = train[train.enrl_tot < 13000]\n",
    "\n",
    "#np.sort(-train_1.enrl_tot)[0:10]\n",
    "\n",
    "#independent variables (log transformation)\n",
    "#train['log_str']=np.log(train['str'])\n",
    "#train['log_cal']=np.log(train['calw_pct'])\n",
    "#train['log_meal']=np.log(train['meal_pct'])\n",
    "#train['log_comp']=np.log(train['computer'])\n",
    "#train['log_comstu']=np.log(train['comp_stu'])\n",
    "#train['log_exp']=np.log(train['expn_stu'])\n",
    "#train['log_avg']=np.log(train['avginc'])\n",
    "#train['log_elpct']=np.log(train['el_pct'])\n",
    "#data cleaning by eliminating NA\n",
    "#train=train[train['log_cal']>=0]\n",
    "train.describe().T\n",
    "\n",
    "#categorical variable\n",
    "#gr_span\n",
    "gr_span_category={'KK-08':1,'KK-06':0}\n",
    "train['gr_span']=train['gr_span'].replace(gr_span_category)\n",
    "train['gr_span'].value_counts()\n",
    "test=['testscr','log_testscr','BoxCoxtest']\n",
    "\n",
    "#Univariate for response variable testscr\n",
    "table1_1=train[test].describe().round(2)\n",
    "table1_1.loc['Skew',:]=train[test].skew()\n",
    "table1_1.loc['Kurt', :]=train[test].kurt()\n",
    "table1_1.to_csv('table1_1.csv')\n",
    "table1_1.round(2)\n",
    "\n",
    "#plot distribution and the boxplot of the responses\n",
    "fig, ax= plt.subplots(2,3, figsize=(18,10))\n",
    "sns.distplot(train['testscr'], ax=ax[0,0], kde=True,hist_kws={'alpha': 0.9}, kde_kws={'color': 'black', 'alpha': 0.6})\n",
    "ax[0,0].set(title='Historgam of test score', xlabel='test_score')\n",
    "sns.boxplot(train['testscr'], data=train, orient='v', ax=ax[1,0])\n",
    "ax[1,0].set(title='Box plot of test score', ylabel='test_score')\n",
    "\n",
    "sns.distplot(train['log_testscr'], ax=ax[0,1], kde=True,hist_kws={'alpha': 0.9}, kde_kws={'color': 'black', 'alpha': 0.6})\n",
    "ax[0,1].set(title='Historgam of Log test score', xlabel='Log_test_score')\n",
    "sns.boxplot(train['log_testscr'], data=train, orient='v', ax=ax[1,1])\n",
    "ax[1,1].set(title='Box plot of Log test score', ylabel='Log_test_score')\n",
    "\n",
    "sns.distplot(train['BoxCoxtest'], ax=ax[0,2], kde=True,hist_kws={'alpha': 0.9}, kde_kws={'color': 'black', 'alpha':\n",
    "0.6})\n",
    "ax[0,2].set(title='Historgam of Box-Cox Test Score', xlabel='Box-Cox Test Score')\n",
    "sns.boxplot(train['BoxCoxtest'], data=train, orient='v', ax=ax[1,2])\n",
    "ax[1,2].set(title='Box plot of Box-Cox Test Score', ylabel='Box-Cox Test Score')\n",
    "plt.show()\n",
    "fig.savefig(\"1.1.png\",format=\"png\",dpi=250)\n",
    "\n",
    "#seems to have an outlier in the response variable, let's detect it\n",
    "\n",
    "train['z_score']=stats.zscore(train['testscr'])\n",
    "z = np.abs(stats.zscore(train['testscr']))\n",
    "print(z)\n",
    "np.max(train['z_score'])\n",
    "\n",
    "#threshold = 3\n",
    "#print(np.where(z > 3))\n",
    "train = train.loc[train['z_score'].abs()<=2.7]\n",
    "\n",
    "#with categorical variables\n",
    "table1_2=train.groupby('gr_span')['testscr'].describe().unstack()\n",
    "table1_2.round(2)\n",
    "sns.boxplot(train['gr_span'],train['testscr'],palette='Blues')\n",
    "\n",
    "#based on the graph, the log test score have some distinctions between span of district 0 and 1\n",
    "#the span of 0 has much higher average scores compared to span of 1\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.hist(residuals,bins=20)\n",
    "ax.set(title='Linear-residual historical graph',ylabel='Freq',xlabel='Resid')\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(25,20))\n",
    "\n",
    "sns.heatmap(train.corr(),square=True,annot=True,cmap='gist_earth_r')\n",
    "plt.title('correlation matrix')\n",
    "\n",
    "\n",
    "formula = 'testscr ~ str + meal_pct + comp_stu + expn_stu + avginc + el_pct'\n",
    "ols2 = smf.ols(formula=formula, data=train).fit()\n",
    "print(ols2.summary())\n",
    "resid = ols2.resid\n",
    "fitted = ols2.fittedvalues\n",
    "\n",
    "#vif multi correlaity.   > 都小于5 甚至小于 3。平均数小于3 > 共线性不严重\n",
    "features= train[['str','meal_pct','avginc']]\n",
    "features=sm.add_constant(features)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif=[]\n",
    "for i in range(3):\n",
    "    vif.append(variance_inflation_factor(features.values,i+1))\n",
    "\n",
    "print(vif)\n",
    "\n",
    "\n",
    "sum(vif)/len(vif)\n",
    "\n",
    "pred3_1=ols2.predict(train)\n",
    "residuals=ols2.resid\n",
    "\n",
    "fitted=pred3_1\n",
    "\n",
    "fig, ax= plt.subplots(2,2, figsize=(14,10))\n",
    "sns.regplot(fitted, residuals, fit_reg=False, ax=ax[0,0], scatter_kws={'alpha':0.5}) \n",
    "ax[0,0].set_xlabel('predicteded values')\n",
    "ax[0,0].set_ylabel('Residuals')\n",
    "ax[0,0].set_title('predicted values against residuals', fontsize=12)\n",
    "sns.regplot(fitted, residuals**2, fit_reg=False, ax=ax[0,1]) \n",
    "ax[0,1].set_xlabel('predicteded values') \n",
    "ax[0,1].set_ylabel('Squared residuals')\n",
    "ax[0,1].set_title('predicteded values vs squared residuals')\n",
    "#sns.boxplot(residuals, orient='h', ax=ax[0,1]) #ax[0,1].set_title('Box plot for the residuals', fontsize=12)\n",
    "sns.distplot(residuals, ax=ax[1,0], hist_kws={'alpha': 0.9}, kde_kws={'color': 'black', 'alpha': 0.6}) \n",
    "ax[1,0].set(title='Residual histogram')\n",
    "pp = sm.ProbPlot(residuals, fit=True)\n",
    "qq = pp.qqplot(color=sns.color_palette('Blues')[-1], alpha=0.8, ax=ax[1,1]) \n",
    "a=ax[1,1].get_xlim()[0]\n",
    "b=ax[1,1].get_xlim()[1]\n",
    "ax[1,1].plot([a,b],[a,b], color='black', alpha=0.6)\n",
    "ax[1,1].set_xlim(-6,6)\n",
    "ax[1,1].set_ylim(-6,6)\n",
    "ax[1,1].set_title('Normal Q-Q plot for the residuals')\n",
    "\n",
    "influence=ols2.get_influence()\n",
    "hat = influence.hat_matrix_diag\n",
    "resid= influence.resid_studentized_external \n",
    "d= influence.cooks_distance[0]\n",
    "dffits= influence.dffits[0]\n",
    "fig, ax= plt.subplots(2, 2, figsize=(15, 10)) \n",
    "ax[0,0].scatter(np.arange(0,len(hat)), hat, s=25)\n",
    "ax[0,0].set_title('Hat values') \n",
    "ax[0,1].scatter(np.arange(0,len(resid)), resid, s=25)\n",
    "ax[0,1].set_title('Studentised residuals')\n",
    "ax[1,0].scatter(np.arange(0,len(d)), d, s=25) \n",
    "ax[1,0].set_title('Cook\\'s distance') \n",
    "ax[1,0].set_xlabel('Index')\n",
    "ax[1,1].scatter(np.arange(0,len(dffits)), dffits, s=25) \n",
    "ax[1,1].set_title('DFFITS') \n",
    "ax[1,1].set_xlabel('Index')\n",
    "\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "sns.regplot(train['str'],resid,lowess=True,ax=ax,scatter_kws={'s':35,'alpha':0.6})\n",
    "ax.set_xlabel('str ',{'fontsize':15})\n",
    "ax.set_ylabel('Residuals ',{'fontsize':15})\n",
    "ax.set_title('Predictor against residuals',{'fontsize':15})\n",
    "plt.axhline(color='Black',alpha=0.3,linestyle='--')\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.hist(resid,bins=20)\n",
    "ax.set(title='Linear-residual historical graph',ylabel='Freq',xlabel='Resid')\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "sns.regplot(train['expn_stu'],resi3,lowess=True,ax=ax,scatter_kws={'s':35,'alpha':0.6})\n",
    "ax.set_xlabel('expn_stu ',{'fontsize':15})\n",
    "ax.set_ylabel('Residuals ',{'fontsize':15})\n",
    "ax.set_title('Predictor against residuals',{'fontsize':15})\n",
    "plt.axhline(color='Black',alpha=0.3,linestyle='--')\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "sns.regplot(train['logged_expn'],resi3,lowess=True,ax=ax,scatter_kws={'s':35,'alpha':0.6})\n",
    "ax.set_xlabel('logged_expn ',{'fontsize':15})\n",
    "ax.set_ylabel('Residuals ',{'fontsize':15})\n",
    "ax.set_title('Predictor against residuals',{'fontsize':15})\n",
    "plt.axhline(color='Black',alpha=0.3,linestyle='--')\n",
    "\n",
    "\n",
    "train['log_meal']=np.log(train['meal_pct'])\n",
    "test['log_meal']=np.log(test['meal_pct'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "sns.regplot(train['meal_pct'],resi3,lowess=True,ax=ax,scatter_kws={'s':35,'alpha':0.6})\n",
    "ax.set_xlabel('meal_pct ',{'fontsize':15})\n",
    "ax.set_ylabel('Residuals ',{'fontsize':15})\n",
    "ax.set_title('Predictor against residuals',{'fontsize':15})\n",
    "plt.axhline(color='Black',alpha=0.3,linestyle='--')\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "sns.regplot(train['log_meal'],resi3,lowess=True,ax=ax,scatter_kws={'s':35,'alpha':0.6})\n",
    "ax.set_xlabel('log_meal ',{'fontsize':15})\n",
    "ax.set_ylabel('Residuals ',{'fontsize':15})\n",
    "ax.set_title('Predictor against residuals',{'fontsize':15})\n",
    "plt.axhline(color='Black',alpha=0.3,linestyle='--')\n",
    "\n",
    "formula3 = 'testscr ~ logged_inc + str+ el_pct +logged_expn + calw_pct + meal_pct +gr_span + gr_calw + str_el'\n",
    "ols3 = smf.ols(formula=formula3,data=train).fit()\n",
    "resi3=ols3.resid\n",
    "fitted3=ols3.fittedvalues\n",
    "print(ols3.summary())\n",
    "\n",
    "import forward_selection \n",
    "model_forward = forward_selection.forward_selected(train[['logged_inc','str','el_pct','logged_expn','calw_pct','meal_pct','gr_span','gr_calw','str_el','testscr']],'testscr',nominated=[])\n",
    "\n",
    "formula3 = 'testscr ~ meal_pct + logged_inc + str_el + gr_span + logged_expn + calw_pct + el_pct + str + 1'\n",
    "ols3 = smf.ols(formula=formula3,data=train).fit()\n",
    "resi3=ols3.resid\n",
    "fitted3=ols3.fittedvalues\n",
    "print(ols3.summary())\n",
    "rmse3=ols3.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "import backward_selection \n",
    "model_backward = backward_selection.backward_selected(train[['logged_inc','str','el_pct','logged_expn','calw_pct','meal_pct','gr_span','gr_calw','str_el','testscr']],'testscr',nominated=[])\n",
    "\n",
    "formula3 = 'testscr ~ el_pct + gr_span + meal_pct + calw_pct + logged_inc + str_el + str + 1'\n",
    "ols3 = smf.ols(formula=formula3,data=train).fit()\n",
    "resi3=ols3.resid\n",
    "fitted3=ols3.fittedvalues\n",
    "print(ols3.summary())\n",
    "rmse3=ols3.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "\n",
    "train['sqrt_el']=np.sqrt(train['el_pct'])\n",
    "test['sqrt_el']=np.sqrt(test['el_pct'])\n",
    "\n",
    "\n",
    "\n",
    "formula3 = 'testscr ~ str + meal_pct + avginc +calw_pct + sqrt_el '\n",
    "ols3 = smf.ols(formula=formula3,data=train).fit()\n",
    "resi3=ols3.resid\n",
    "fitted3=ols3.fittedvalues\n",
    "print(ols3.summary())\n",
    "rmse3=ols3.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "sns.regplot(train['str'],resi3,lowess=True,ax=ax,scatter_kws={'s':35,'alpha':0.6})\n",
    "ax.set_xlabel('str ',{'fontsize':15})\n",
    "ax.set_ylabel('Residuals ',{'fontsize':15})\n",
    "ax.set_title('Predictor against residuals',{'fontsize':15})\n",
    "plt.axhline(color='Black',alpha=0.3,linestyle='--')\n",
    "\n",
    "features= train[['meal_pct','logged_inc','str_el','gr_span','logged_expn','calw_pct','el_pct','str']]\n",
    "features=sm.add_constant(features)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif=[]\n",
    "for i in range(8):\n",
    "    vif.append(variance_inflation_factor(features.values,i+1))\n",
    "\n",
    "print(vif)\n",
    "\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "formula = 'testscr ~ str'\n",
    "ols1 = smf.ols(formula=formula, data=train).fit()\n",
    "print(ols1.summary())\n",
    "residuals=ols1.resid\n",
    "rmse=ols1.mse_resid**0.5\n",
    "print()\n",
    "print()\n",
    "print('rmse=',rmse)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "sns.regplot(train['str'],residuals,lowess=True,ax=ax,scatter_kws={'s':35,'alpha':0.6})\n",
    "#residual \n",
    "ax.set_xlabel('str ',{'fontsize':15})\n",
    "ax.set_ylabel('Residuals ',{'fontsize':15})\n",
    "ax.set_title('Predictor against residuals',{'fontsize':15})\n",
    "plt.axhline(color='Black',alpha=0.3,linestyle='--')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#binary analysis\n",
    "#correlation of all variables\n",
    "variables=[ 'testscr',\n",
    "    #'enrl_tot',\n",
    " #'teachers',\n",
    " 'calw_pct',\n",
    " #'meal_pct',\n",
    " 'computer',\n",
    " 'comp_stu',\n",
    " 'expn_stu',\n",
    " 'str',\n",
    " 'avginc',\n",
    " 'el_pct',\n",
    " #'read_scr',\n",
    "# 'math_scr'\n",
    "          ]\n",
    "corr_matrix=data[variables].corr()\n",
    "corr_matrix\n",
    "#tryout different options and demonstrate it in your report\n",
    "# We end up with 7 predictors\n",
    "#'testscr','calw_pct','computer','comp_stu','expn_stu','str','avginc','el_pct',\n",
    "\n",
    "\n",
    "sm.graphics.plot_corr(corr_matrix, xnames=variables)\n",
    "plt.show()\n",
    "\n",
    "#run regression of class size and test scores\n",
    "# Assumption 1: linearity\n",
    "#p = sns.pairplot(train, x_vars=['str'], y_vars='testscr', size=4, aspect=1)\n",
    "sns.regplot(train['str'], train['testscr'], lowess=True)\n",
    "#By looking at the plots we can see that with the test score and class size are not linear\n",
    "# Therefore, linear regression might not be a good fit for the model\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "#choose the variable to run regression\n",
    "x = train['str'].values.reshape(-1,1)\n",
    "y = train['testscr'].values.reshape(-1,1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(x)\n",
    "\n",
    "#split test and train set, in here 20% is the test set--you can explore different split(0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train,y_train)\n",
    "y_pred = regr.predict(X_train)\n",
    "\n",
    "#Residuals as we know are the differences between the true value and the predicted value. \n",
    "#One of the assumptions of linear regression is that the mean of the residuals should be zero.\n",
    "\n",
    "residuals = y_train-y_pred\n",
    "mean_residuals = np.mean(residuals)\n",
    "print(\"Mean of Residuals {}\".format(mean_residuals))\n",
    "#very close to zero so all good here\n",
    "\n",
    "\n",
    "\n",
    "#homoscedasticity\n",
    "plt.scatter(np.array(y_pred),np.array(residuals))\n",
    "\n",
    "plt.xlabel('y_pred/predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.ylim(-50,60)\n",
    "plt.xlim(640,660)\n",
    "p = sns.lineplot([0,660],[0,0],color='blue')\n",
    "p = plt.title('Residuals vs fitted values plot for homoscedasticity check')\n",
    "\n",
    "#Goldfeld Quandt Test\n",
    "#Checking heteroscedasticity : Using Goldfeld Quandt we test for heteroscedasticity.\n",
    "\n",
    "#Null Hypothesis: Error terms are homoscedastic\n",
    "#Alternative Hypothesis: Error terms are heteroscedastic.\n",
    "#Since p value is more than 0.05 in Goldfeld Quandt Test, \n",
    "#we can't reject it's null hypothesis that error terms are homoscedastic.\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "name = ['F statistic', 'p-value']\n",
    "test = sms.het_goldfeldquandt(residuals, X_train)\n",
    "lzip(name, test)\n",
    "\n",
    "#There should not be autocorrelation in the data so the error terms should not form any pattern\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(np.array(y_pred),np.array(residuals))\n",
    "#p = plt.lineplot(y_pred,residuals,marker='o',color='blue')\n",
    "plt.xlabel('y_pred/predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.ylim(-50,60)\n",
    "plt.xlim(640,660)\n",
    "p = sns.lineplot([0,660],[0,0],color='blue')\n",
    "p = plt.title('Residuals vs fitted values plot for autocorrelation check')\n",
    "\n",
    "#Ljungbox test\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "min(diag.acorr_ljungbox(residuals , lags = 40)[1])\n",
    "\n",
    "#Null Hypothesis: Autocorrelation is absent.\n",
    "#Alternative Hypothesis: Autocorrelation is present.\n",
    "#Since p value is greater than 0.05 \n",
    "#we fail to reject the null hypothesis.\n",
    "\n",
    "#Ljungbox test\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "min(diag.acorr_ljungbox(residuals , lags = 40)[1])\n",
    "\n",
    "#Null Hypothesis: Autocorrelation is absent.\n",
    "#Alternative Hypothesis: Autocorrelation is present.\n",
    "#Since p value is greater than 0.05 \n",
    "#we fail to reject the null hypothesis.\n",
    "\n",
    "model = smf.ols(formula='testscr ~ str', data=train)\n",
    "reg = model.fit()\n",
    "print(reg.summary())\n",
    "#based on r-square and p value, we know it is a very bad model\n",
    "\n",
    "#run models\n",
    "formula = 'testscr ~ str + meal_pct +calw_pct+ computer+ comp_stu + expn_stu + avginc + el_pct'\n",
    "ols2 = smf.ols(formula=formula, data=train).fit()\n",
    "print(ols2.summary())\n",
    "resid = ols2.resid\n",
    "fitted = ols2.fittedvalues\n",
    "\n",
    "features= train[['str', 'meal_pct', 'calw_pct','computer','comp_stu', 'expn_stu', 'avginc', 'el_pct']]\n",
    "features=sm.add_constant(features)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif=[]\n",
    "for i in range(8):\n",
    "    vif.append(variance_inflation_factor(features.values,i+1))\n",
    "\n",
    "print(vif)\n",
    "#mealpct vif>5, should be eliminated\n",
    "\n",
    "formula = 'testscr ~ str + calw_pct+ computer+ comp_stu + expn_stu + avginc + el_pct'\n",
    "ols3 = smf.ols(formula=formula, data=train).fit()\n",
    "print(ols3.summary())\n",
    "resid = ols3.resid\n",
    "fitted = ols3.fittedvalues\n",
    "#r-squared reduced, but str does not become more significant, so it might not be a big deal to include the variable\n",
    "\n",
    "rmse3=ols3.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "formula = 'testscr ~ str + meal_pct +calw_pct+ computer+ comp_stu + expn_stu + avginc + el_pct+gr_calw+str_span'\n",
    "ols2 = smf.ols(formula=formula, data=train).fit()\n",
    "print(ols2.summary())\n",
    "resid2 = ols2.resid\n",
    "fitted2 = ols2.fittedvalues\n",
    "\n",
    "#best\n",
    "\n",
    "rmse3=ols2.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "influence=ols2.get_influence()\n",
    "hat = influence.hat_matrix_diag\n",
    "resid= influence.resid_studentized_external \n",
    "d= influence.cooks_distance[0]\n",
    "dffits= influence.dffits[0]\n",
    "fig, ax= plt.subplots(2, 2, figsize=(15, 10)) \n",
    "ax[0,0].scatter(np.arange(0,len(hat)), hat, s=25)\n",
    "ax[0,0].set_title('Hat values') \n",
    "ax[0,1].scatter(np.arange(0,len(resid)), resid, s=25)\n",
    "ax[0,1].set_title('Studentised residuals')\n",
    "ax[1,0].scatter(np.arange(0,len(d)), d, s=25) \n",
    "ax[1,0].set_title('Cook\\'s distance') \n",
    "ax[1,0].set_xlabel('Index')\n",
    "ax[1,1].scatter(np.arange(0,len(dffits)), dffits, s=25) \n",
    "ax[1,1].set_title('DFFITS') \n",
    "ax[1,1].set_xlabel('Index')\n",
    "\n",
    "pred3_1=ols2.predict(train)\n",
    "residuals=ols2.resid\n",
    "\n",
    "fitted=pred3_1\n",
    "\n",
    "fig, ax= plt.subplots(2,2, figsize=(14,10))\n",
    "sns.regplot(fitted, residuals, fit_reg=False, ax=ax[0,0], scatter_kws={'alpha':0.5}) \n",
    "ax[0,0].set_xlabel('predicteded values')\n",
    "ax[0,0].set_ylabel('Residuals')\n",
    "ax[0,0].set_title('predicted values against residuals', fontsize=12)\n",
    "sns.regplot(fitted, residuals**2, fit_reg=False, ax=ax[0,1]) \n",
    "ax[0,1].set_xlabel('predicteded values') \n",
    "ax[0,1].set_ylabel('Squared residuals')\n",
    "ax[0,1].set_title('predicteded values vs squared residuals')\n",
    "#sns.boxplot(residuals, orient='h', ax=ax[0,1]) #ax[0,1].set_title('Box plot for the residuals', fontsize=12)\n",
    "sns.distplot(residuals, ax=ax[1,0], hist_kws={'alpha': 0.9}, kde_kws={'color': 'black', 'alpha': 0.6}) \n",
    "ax[1,0].set(title='Residual histogram')\n",
    "pp = sm.ProbPlot(residuals, fit=True)\n",
    "qq = pp.qqplot(color=sns.color_palette('Blues')[-1], alpha=0.8, ax=ax[1,1]) \n",
    "a=ax[1,1].get_xlim()[0]\n",
    "b=ax[1,1].get_xlim()[1]\n",
    "ax[1,1].plot([a,b],[a,b], color='black', alpha=0.6)\n",
    "ax[1,1].set_xlim(-6,6)\n",
    "ax[1,1].set_ylim(-6,6)\n",
    "ax[1,1].set_title('Normal Q-Q plot for the residuals')\n",
    "\n",
    "pred3_1=ols2.predict(train)\n",
    "residuals=ols2.resid\n",
    "\n",
    "fitted=pred3_1\n",
    "\n",
    "fig, ax= plt.subplots(2,2, figsize=(14,10))\n",
    "sns.regplot(fitted, residuals, fit_reg=False, ax=ax[0,0], scatter_kws={'alpha':0.5}) \n",
    "ax[0,0].set_xlabel('predicteded values')\n",
    "ax[0,0].set_ylabel('Residuals')\n",
    "ax[0,0].set_title('predicted values against residuals', fontsize=12)\n",
    "sns.regplot(fitted, residuals**2, fit_reg=False, ax=ax[0,1]) \n",
    "ax[0,1].set_xlabel('predicteded values') \n",
    "ax[0,1].set_ylabel('Squared residuals')\n",
    "ax[0,1].set_title('predicteded values vs squared residuals')\n",
    "#sns.boxplot(residuals, orient='h', ax=ax[0,1]) #ax[0,1].set_title('Box plot for the residuals', fontsize=12)\n",
    "sns.distplot(residuals, ax=ax[1,0], hist_kws={'alpha': 0.9}, kde_kws={'color': 'black', 'alpha': 0.6}) \n",
    "ax[1,0].set(title='Residual histogram')\n",
    "pp = sm.ProbPlot(residuals, fit=True)\n",
    "qq = pp.qqplot(color=sns.color_palette('Blues')[-1], alpha=0.8, ax=ax[1,1]) \n",
    "a=ax[1,1].get_xlim()[0]\n",
    "b=ax[1,1].get_xlim()[1]\n",
    "ax[1,1].plot([a,b],[a,b], color='black', alpha=0.6)\n",
    "ax[1,1].set_xlim(-6,6)\n",
    "ax[1,1].set_ylim(-6,6)\n",
    "ax[1,1].set_title('Normal Q-Q plot for the residuals')\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "sns.regplot(train['str'],residuals,lowess=True,ax=ax,scatter_kws={'s':35,'alpha':0.6})\n",
    "ax.set_xlabel('str ',{'fontsize':15})\n",
    "ax.set_ylabel('Residuals ',{'fontsize':15})\n",
    "ax.set_title('Predictor against residuals',{'fontsize':15})\n",
    "plt.axhline(color='Black',alpha=0.3,linestyle='--')\n",
    "\n",
    "features= train[['str' , 'meal_pct' ,'calw_pct' ,'computer' ,'comp_stu','expn_stu','avginc','el_pct','gr_calw','str_span']]\n",
    "features=sm.add_constant(features)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif=[]\n",
    "for i in range(10):\n",
    "    vif.append(variance_inflation_factor(features.values,i+1))\n",
    "\n",
    "print(vif)\n",
    "\n",
    "formula = 'testscr ~ str + str_span+gr_computer+expn_stu+el_pct+np.power(el_pct, 2)+calw_pct'\n",
    "ols7 = smf.ols(formula=formula, data=train).fit()\n",
    "print(ols7.summary())\n",
    "resid7 = ols7.resid\n",
    "fitted7 = ols7.fittedvalues\n",
    "\n",
    "\n",
    "rmse3=ols7.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "formula = 'testscr ~ str + str_span+gr_computer+expn_stu+el_pct+np.power(el_pct, 2)+avginc'\n",
    "ols8 = smf.ols(formula=formula, data=train).fit()\n",
    "print(ols8.summary())\n",
    "resid8 = ols8.resid\n",
    "fitted8 = ols8.fittedvalues\n",
    "\n",
    "rmse3=ols8.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "#prediction\n",
    "formula = 'testscr ~ str + meal_pct +calw_pct+ computer+ comp_stu + expn_stu + avginc + el_pct+gr_calw+str_span'\n",
    "ols2 = smf.ols(formula=formula, data=train).fit()\n",
    "print(ols2.summary())\n",
    "resid = ols2.resid\n",
    "fitted = ols2.fittedvalues\n",
    "\n",
    "\n",
    "rmse3=ols2.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "\n",
    "gr_span_category={'KK-08':1,'KK-06':0}\n",
    "test['gr_span']=test['gr_span'].replace(gr_span_category)\n",
    "test['gr_span'].value_counts()\n",
    "\n",
    "\n",
    "test['gr_calw']=test['gr_span']* test['calw_pct']\n",
    "test['str_span']=test['str']* test['gr_span']\n",
    "test['gr_computer']=test['gr_span']* test['computer']\n",
    "\n",
    "train['gr_calw']=train['gr_span']* train['calw_pct']\n",
    "train['str_span']=train['str']* train['gr_span']\n",
    "train['gr_computer']=train['gr_span']* train['computer']\n",
    "\n",
    "formula = 'testscr ~ str + meal_pct +calw_pct+ computer+ comp_stu + expn_stu + avginc + el_pct+gr_calw+str_span'\n",
    "ols2 = smf.ols(formula=formula, data=train).fit()\n",
    "print(ols2.summary())\n",
    "resid2 = ols2.resid\n",
    "fitted2 = ols2.fittedvalues\n",
    "\n",
    "#best\n",
    "\n",
    "rmse3=ols2.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "formula3 = 'testscr ~str+ meal_pct+calw_pct+computer+comp_stu+expn_stu+avginc+el_pct+gr_calw+str_span'\n",
    "ols3 = smf.ols(formula=formula3,data=test).fit()\n",
    "resi3=ols3.resid\n",
    "fitted3=ols3.fittedvalues\n",
    "print(ols3.summary())\n",
    "rmse3=ols3.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "yp_fs1k=ols2.predict({'str': test['str'],'meal_pct':test['meal_pct'],'calw_pct': test['calw_pct'],'computer': test['computer'],'comp_stu': test['comp_stu'],'expn_stu': test['expn_stu'],'avginc': test['avginc'],'el_pct': test['el_pct'],'gr_calw': test['gr_calw'],'str_span': test['str_span']})\n",
    "tableau=['#1F77B4', '#FF7F0E', '#2CA02C', '#DB2728', '#9467BD', '#8c564b', '#e377c2', '#7f7f7f']\n",
    "\n",
    "plt.scatter(test['calw_pct'], test['testscr'], color=tableau[1])\n",
    "plt.scatter(test['calw_pct'], yp_fs1k)\n",
    "# plt.scatter(test['calw_pct'], ols3, color=tableau[2])\n",
    "\n",
    "train['sqrt_el']=np.sqrt(train['el_pct'])\n",
    "test['sqrt_el']=np.sqrt(test['el_pct'])\n",
    "\n",
    "\n",
    "\n",
    "formula3 = 'testscr ~ str + meal_pct + avginc +calw_pct + sqrt_el '\n",
    "ols3 = smf.ols(formula=formula3,data=test).fit()\n",
    "resi3=ols3.resid\n",
    "fitted3=ols3.fittedvalues\n",
    "print(ols3.summary())\n",
    "rmse3=ols3.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "tableau=['#1F77B4', '#FF7F0E', '#2CA02C', '#DB2728', '#9467BD', '#8c564b', '#e377c2', '#7f7f7f']\n",
    "\n",
    "plt.scatter(test['calw_pct'], test['testscr'], color=tableau[1])\n",
    "plt.scatter(test['calw_pct'], yp_fs1k)\n",
    "# plt.scatter(test['calw_pct'], ols3, color=tableau[2])\n",
    "\n",
    "test['gr_calw']=test['gr_span']* test['calw_pct']\n",
    "test['str_el']=test['str']* test['el_pct']\n",
    "\n",
    "formula3 = 'testscr ~ logged_inc + str+ el_pct +logged_expn + calw_pct + meal_pct +gr_span + gr_calw + str_el'\n",
    "ols4 = smf.ols(formula=formula3,data=test).fit()\n",
    "resi4=ols4.resid\n",
    "fitted3=ols4.fittedvalues\n",
    "print(ols4.summary())\n",
    "rmse3=ols4.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "yp_fs1k=ols3.predict({'logged_inc': test['logged_inc'],'str':test['str'],'el_pct': test['el_pct'],'logged_expn': test['logged_expn'],'calw_pct': test['calw_pct'],'meal_pct': test['meal_pct'],'gr_span': test['gr_span'],'gr_calw': test['gr_calw'],'str_el': test['str_el']})\n",
    "tableau=['#1F77B4', '#FF7F0E', '#2CA02C', '#DB2728', '#9467BD', '#8c564b', '#e377c2', '#7f7f7f']\n",
    "\n",
    "plt.scatter(test['calw_pct'], test['testscr'], color=tableau[1])\n",
    "plt.scatter(test['calw_pct'], yp_fs1k)\n",
    "# plt.scatter(test['calw_pct'], ols3, color=tableau[2])\n",
    "\n",
    "formula3 = 'testscr ~ meal_pct + logged_inc + str_el + gr_span + logged_expn + calw_pct + el_pct + str + 1'\n",
    "ols3 = smf.ols(formula=formula3,data=test).fit()\n",
    "resi3=ols3.resid\n",
    "fitted3=ols3.fittedvalues\n",
    "print(ols3.summary())\n",
    "rmse3=ols3.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "yp_fs1k=ols3.predict({'meal_pct': test['meal_pct'],'logged_inc':test['logged_inc'],'str_el': test['str_el'],'gr_span': test['gr_span'],'logged_expn': test['logged_expn'],'calw_pct': test['calw_pct'],'el_pct': test['el_pct'],'str': test['str']})\n",
    "tableau=['#1F77B4', '#FF7F0E', '#2CA02C', '#DB2728', '#9467BD', '#8c564b', '#e377c2', '#7f7f7f']\n",
    "\n",
    "plt.scatter(test['calw_pct'], test['testscr'], color=tableau[1])\n",
    "plt.scatter(test['calw_pct'], yp_fs1k)\n",
    "# plt.scatter(test['calw_pct'], ols3, color=tableau[2])\n",
    "\n",
    "formula3 = 'testscr ~ el_pct + gr_span + meal_pct + calw_pct + logged_inc + str_el + str + 1'\n",
    "ols3 = smf.ols(formula=formula3,data=test).fit()\n",
    "resi3=ols3.resid\n",
    "fitted3=ols3.fittedvalues\n",
    "print(ols3.summary())\n",
    "rmse3=ols3.mse_resid**0.5\n",
    "print('rmse= ',rmse3)\n",
    "\n",
    "yp_fs1k=ols3.predict({'el_pct': test['el_pct'],'gr_span':test['gr_span'],'meal_pct': test['meal_pct'],'calw_pct': test['calw_pct'],'logged_inc': test['logged_inc'],'str_el': test['str_el'],'str': test['str']})\n",
    "tableau=['#1F77B4', '#FF7F0E', '#2CA02C', '#DB2728', '#9467BD', '#8c564b', '#e377c2', '#7f7f7f']\n",
    "\n",
    "plt.scatter(test['calw_pct'], test['testscr'], color=tableau[1])\n",
    "plt.scatter(test['calw_pct'], yp_fs1k)\n",
    "# plt.scatter(test['calw_pct'], ols3, color=tableau[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
